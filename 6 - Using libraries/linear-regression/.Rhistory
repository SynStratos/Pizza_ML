ind <- sample(2, nrow(data_zs), replace=TRUE, prob= c(0.8,0.2))
training <- data_zs[ind==1,]
test <- data_zs[ind==2,]
# training model
my_formula <- as.formula(paste(names(training)[12], " ~ ", paste(names(training)[-12], collapse= "+")))
my_model <- lm(formula = my_formula,
data = training)
my_model
# apply model on test set
result_1 <- predict(my_model, test)
result_1
help("lm")
rm(list=ls())
# import data
data <- read.csv("wine.csv", header=F)
colnames(data) <- c("fixed_acidity", "volatile_acidity", "citric_acid", "residual_sugar", "chlorides",
"free_sulfur_dioxide", "total_sulfur_dioxide", "density", "pH", "sulphates", "alcohol", "quality")
# min-max normalization
data_mm <- data
data_mm[1:11] <- lapply( data[-12], function(x) round((x-min(x))/(max(x)-min(x)), 1))
# z-score normalization
data_zs <- data
data_zs[1:11] <- lapply( data[-12], function(x) round((x-mean(x))/sd(x), 1))
# split data 80/20
set.seed(123)
ind <- sample(2, nrow(data_zs), replace=TRUE, prob= c(0.8,0.2))
training <- data_zs[ind==1,]
test <- data_zs[ind==2,]
# training model
my_formula <- as.formula(paste(names(training)[12], " ~ ", paste(names(training)[-12], collapse= "+")))
# details in help("lm")
my_model <- lm(formula = my_formula,
data = training)
# apply model on test set
result_1 <- predict(my_model, test)
head(result_1)
View(data)
View(data)
# evaluation
RMSE <- sqrt(mean((result_1 -test[12])^2))
# evaluation
RMSE <- sqrt(mean((t(result_1) - test[12])^2))
result_1 - test[12]
# evaluation
error <- result_1 - test[12]
RMSE <- sqrt(mean((error)^2))
mean(error)
# evaluation
error <- result_1 - test[12]
mean(error)
mean(error[1])
# evaluation
error <- as.data.frame(result_1) - test[12]
mean(error[1])
# evaluation
error <- result_1 -as.matrix(test[12])
mean(error)
# evaluation
error <- result_1 -as.matrix(test[12])
RMSE <- sqrt(mean((error)^2))
# evaluation
error <- result_1 - test$quality
RMSE <- sqrt(mean((error)^2))
summ <- summary(my_model)
summ <- summary(my_model)$r.squared
summary(my_model)
MAE <- mean(error)
MSE <- mean(error)^2
RMSE <- sqrt(mean((error)^2))
# aggiungere quadrati delle feature
squared_features <- lapply( data[-12], function(x) (x^2))
# z-score normalization
mu <- apply(data[-12], 2, mean)
std <- apply(data[-12], 2, sd)
#data_zs[1:11] <- lapply( data[-12], function(x) round((x-mean(x))/sd(x), 1))
data_zd[1:11] <- sweep(sweep(data[-12], 2L, mu), 2, std, "/")
data_zs <- data
# z-score normalization
mu <- apply(data[-12], 2, mean)
std <- apply(data[-12], 2, sd)
data_zs <- data
#data_zs[1:11] <- lapply( data[-12], function(x) round((x-mean(x))/sd(x), 1))
data_zs[1:11] <- sweep(sweep(data[-12], 2L, mu), 2, std, "/")
# min-max normalization
min <- apply(data[-12], 2, min)
max <- apply(data[-12], 2, max)
data_mm <- data
help("sweep")
#data_zs[1:11] <- lapply( data[-12], function(x) round((x-mean(x))/sd(x), 1))
data_zs[1:11] <- sweep(sweep(data[-12], 2L, mu, "-"), 2, std, "/")
# z-score normalization
mu <- apply(data[-12], 2, mean)
std <- apply(data[-12], 2, sd)
data_zs <- data
data_zs[1:11] <- lapply( data[-12], function(x) round((x-mean(x))/sd(x), 1))
data_zs2[1:11] <- sweep(sweep(data[-12], 2L, mu, "-"), 2, std, "/")
View(data_mm)
View(data_mm)
View(data_zs)
View(data_zs)
data_zs2 <- data
data_zs2[1:11] <- sweep(sweep(data[-12], 2L, mu, "-"), 2, std, "/")
View(data_zs2)
View(data_zs2)
data_zs2 <- data
data_zs2[1:11] <- sweep(sweep(data[-12], 2L, mu), 2, std, "/")
View(data_zs2)
View(data_zs2)
data_zs2 <- data
data_zs2[1:11] <- sweep(sweep(data[-12], 2L, mu, "-"), 2, std, "/")
View(data_zs2)
View(data_zs2)
data_zs <- data
data_zs[1:11] <- lapply( data[-12], function(x) round((x-mean(x))/sd(x), 1))
data_zs2 <- data
data_zs2[1:11] <- sweep(sweep(data[-12], 2L, mu, "-"), 2, std, "/")
data_zs3 <- data
data_zs3[1:11] <- sweep(sweep(data[-12], 2L, mu), 2, std, "/")
View(data_zs)
View(data_zs)
View(data_zs2)
View(data_zs2)
View(data_zs3)
View(data_zs3)
rm(list=ls())
# import data
data <- read.csv("wine.csv", header=F)
colnames(data) <- c("fixed_acidity", "volatile_acidity", "citric_acid", "residual_sugar", "chlorides",
"free_sulfur_dioxide", "total_sulfur_dioxide", "density", "pH", "sulphates", "alcohol", "quality")
# min-max normalization
min <- apply(data[-12], 2, min)
max <- apply(data[-12], 2, max)
data_mm <- data
#data_mm[1:11] <- lapply( data[-12], function(x) round((x-min(x))/(max(x)-min(x)), 1))
data_mm[1:11] <- sweep()
# z-score normalization
mu <- apply(data[-12], 2, mean)
std <- apply(data[-12], 2, sd)
data_zs <- data
# data_zs[1:11] <- lapply( data[-12], function(x) round((x-mean(x))/sd(x), 1))
data_zs[1:11] <- sweep(sweep(data[-12], 2L, mu), 2, std, "/") # come all'esercitazione
# split data 80/20
set.seed(123)
ind <- sample(2, nrow(data_zs), replace=TRUE, prob= c(0.8,0.2))
training <- data_zs[ind==1,]
test <- data_zs[ind==2,]
# training model
my_formula <- as.formula(paste(names(training)[12], " ~ ", paste(names(training)[-12], collapse= "+")))
# details in help("lm")
my_model <- lm(formula = my_formula,
data = training)
# apply model on test set
result_1 <- predict(my_model, test)
# evaluation
error <- result_1 - test$quality
MAE <- mean(error)
MSE <- mean(error)^2
RMSE <- sqrt(mean((error)^2))
R2 <- summary(my_model)$r.squared
View(training)
View(training)
View(test)
View(test)
# apply model on new sample
test = data.frame(t(c(6.0, 0.31, 0.47, 3.6, 0.067, 18.0, 42.0, 0.99549, 3.39, 0.66, 11.0))
# apply model on new sample
test = data.frame(t(c(6.0, 0.31, 0.47, 3.6, 0.067, 18.0, 42.0, 0.99549, 3.39, 0.66, 11.0)))
# apply model on new sample
test = data.frame(t(c(6.0, 0.31, 0.47, 3.6, 0.067, 18.0, 42.0, 0.99549, 3.39, 0.66, 11.0)))
names(test) = c("fixed acidity", "volatile acidity", "citric acid", "residual sugar", "chlorides", "free sulfur dioxide", "total sulfur dioxide",
"density", "pH", "sulphates", "alcohol")
# apply model on new sample
sample = data.frame(t(c(6.0, 0.31, 0.47, 3.6, 0.067, 18.0, 42.0, 0.99549, 3.39, 0.66, 11.0)))
names(sample) = c("fixed acidity", "volatile acidity", "citric acid", "residual sugar", "chlorides", "free sulfur dioxide", "total sulfur dioxide",
"density", "pH", "sulphates", "alcohol")
result_sample <- predict(my_model, sample)
# apply model on new sample
sample <- data.frame(t(c(6.0, 0.31, 0.47, 3.6, 0.067, 18.0, 42.0, 0.99549, 3.39, 0.66, 11.0)))
names(sample) <- c("fixed_acidity", "volatile_acidity", "citric_acid", "residual_sugar", "chlorides",
"free_sulfur dioxide", "total_sulfur_dioxide", "density", "pH", "sulphates", "alcohol")
result_sample <- predict(my_model, sample)
# apply model on new sample
sample <- data.frame(t(c(6.0, 0.31, 0.47, 3.6, 0.067, 18.0, 42.0, 0.99549, 3.39, 0.66, 11.0)))
names(sample) <- c("fixed_acidity", "volatile_acidity", "citric_acid", "residual_sugar", "chlorides",
"free_sulfur_dioxide", "total_sulfur_dioxide", "density", "pH", "sulphates", "alcohol")
result_sample <- predict(my_model, sample)
norm_sample <- sweep(sweep(sample, 2L, mu), 2, std, "/")
norm_sample <- sweep(sweep(sample, 2L, mu), 2, std, "/")
result_norm_sample <- predict(my_model, norm_sample)
# min-max normalization
min <- apply(data[-12], 2, min)
max <- apply(data[-12], 2, max)
diff <- max - min
data_mm <- data
#data_mm[1:11] <- lapply( data[-12], function(x) round((x-min(x))/(max(x)-min(x)), 1))
data_mm[1:11] <- sweep( sweep(data[-12], 2L, min), 2, diff, "/")
View(data_mm)
View(data_mm)
rm(list=ls())
# import data
data <- read.csv("wine.csv", header=F)
colnames(data) <- c("fixed_acidity", "volatile_acidity", "citric_acid", "residual_sugar", "chlorides",
"free_sulfur_dioxide", "total_sulfur_dioxide", "density", "pH", "sulphates", "alcohol", "quality")
# SCEGLIERE UN TIPO DI NORMALIZZAZIONE
# z-score normalization
mu <- apply(data[-12], 2, mean)
std <- apply(data[-12], 2, sd)
data[1:11] <- sweep(sweep(data[-12], 2L, mu), 2, std, "/") # come all'esercitazione
# TRAINING DEL MODELLO
my_model <- lm(data$quality~.,
data)
# APPLICARE IL MODELLO AL NUOVO SAMPLE
sample <- data.frame(t(c(6.0, 0.31, 0.47, 3.6, 0.067, 18.0, 42.0, 0.99549, 3.39, 0.66, 11.0)))
names(sample) <- c("fixed_acidity", "volatile_acidity", "citric_acid", "residual_sugar", "chlorides",
"free_sulfur_dioxide", "total_sulfur_dioxide", "density", "pH", "sulphates", "alcohol")
norm_sample <- sweep(sweep(sample, 2L, mu), 2, std, "/")
result_sample <- predict(my_model, norm_sample)
rm(list=ls())
# import data
data <- read.csv("wine.csv", header=F)
colnames(data) <- c("fixed_acidity", "volatile_acidity", "citric_acid", "residual_sugar", "chlorides",
"free_sulfur_dioxide", "total_sulfur_dioxide", "density", "pH", "sulphates", "alcohol", "quality")
# z-score normalization
mu <- apply(data[-12], 2, mean)
std <- apply(data[-12], 2, sd)
data_zs <- data
# data_zs[1:11] <- lapply( data[-12], function(x) round((x-mean(x))/sd(x), 1))
data_zs[1:11] <- sweep(sweep(data[-12], 2L, mu), 2, std, "/") # come all'esercitazione
# split data 80/20
set.seed(123)
ind <- sample(2, nrow(data_zs), replace=TRUE, prob= c(0.8,0.2))
training <- data_zs[ind==1,]
test <- data_zs[ind==2,]
# training model
my_formula <- as.formula(paste(names(training)[12], " ~ ", paste(names(training)[-12], collapse= "+")))
# details in help("lm")
my_model <- lm(formula = my_formula,
data = training)
# AGGIUNGERE FEATURE CORRISPONDENTE A fixed_acidity*pH
new_feature <- data$pH * data$fixed_acidity
data <- cbind(data[1:11], new_feature, data[12])
name(data[12]) <-"ph*acidity"
colnames(data[12]) <-"ph*acidity"
View(data)
View(data)
colnames(data$new_feature) <-"ph*acidity"
names(data$new_feature) <-"ph*acidity"
View(data)
View(data)
#------------AGGIUNGERE FEATURE CORRISPONDENTE A fixed_acidity*pH------------#
rm(list=ls())
# import data
data <- read.csv("wine.csv", header=F)
colnames(data) <- c("fixed_acidity", "volatile_acidity", "citric_acid", "residual_sugar", "chlorides",
"free_sulfur_dioxide", "total_sulfur_dioxide", "density", "pH", "sulphates", "alcohol", "quality")
new_feature <- data$pH * data$fixed_acidity
data <- cbind(data[1:11], new_feature, data[12])
mu <- apply(data[-13], 2, mean)
std <- apply(data[-13], 2, sd)
data[1:12] <- sweep(sweep(data[-13], 2L, mu), 2, std, "/")
my_model <- lm(data$quality ~., data)
sample <- data.frame(t(c(6.0, 0.31, 0.47, 3.6, 0.067, 18.0, 42.0, 0.99549, 3.39, 0.66, 11.0, 6.0*3.39)))
norm_sample <- sweep(sweep(sample, 2L, mu), 2, std, "/")
result_sample <- predict(my_model, norm_sample)
sample <- data.frame(t(c(6.0, 0.31, 0.47, 3.6, 0.067, 18.0, 42.0, 0.99549, 3.39, 0.66, 11.0, 6.0*3.39)))
colnames(data) <- c("fixed_acidity", "volatile_acidity", "citric_acid", "residual_sugar", "chlorides",
"free_sulfur_dioxide", "total_sulfur_dioxide", "density", "pH", "sulphates", "alcohol", "new_feature"," quality")
norm_sample <- sweep(sweep(sample, 2L, mu), 2, std, "/")
result_sample <- predict(my_model, norm_sample)
sample <- data.frame(t(c(6.0, 0.31, 0.47, 3.6, 0.067, 18.0, 42.0, 0.99549, 3.39, 0.66, 11.0, 6.0*3.39)))
colnames(sample) <- c("fixed_acidity", "volatile_acidity", "citric_acid", "residual_sugar", "chlorides",
"free_sulfur_dioxide", "total_sulfur_dioxide", "density", "pH", "sulphates", "alcohol", "new_feature"," quality")
norm_sample <- sweep(sweep(sample, 2L, mu), 2, std, "/")
sample <- data.frame(t(c(6.0, 0.31, 0.47, 3.6, 0.067, 18.0, 42.0, 0.99549, 3.39, 0.66, 11.0, 6.0*3.39)))
colnames(sample) <- c("fixed_acidity", "volatile_acidity", "citric_acid", "residual_sugar", "chlorides",
"free_sulfur_dioxide", "total_sulfur_dioxide", "density", "pH", "sulphates", "alcohol", "new_feature")
norm_sample <- sweep(sweep(sample, 2L, mu), 2, std, "/")
result_sample <- predict(my_model, norm_sample)
#--------------------REGRESSIONE POLINOMIALE MULTIVARIATA--------------------#
#------------AGGIUNGERE FEATURE CORRISPONDENTE A fixed_acidity*pH------------#
rm(list=ls())
rm(list=ls())
# import data
data <- read.csv("wine.csv", header=F)
colnames(data) <- c("fixed_acidity", "volatile_acidity", "citric_acid", "residual_sugar", "chlorides",
"free_sulfur_dioxide", "total_sulfur_dioxide", "density", "pH", "sulphates", "alcohol", "quality")
# aggiungere quadrati delle feature
squared_features <- lapply( data[-12], function(x) (x^2))
# split dataset 70/10/20
ind <- sample(3, nrow(data), replace=TRUE, prob= c(0.7,0.1,0.2))
training <- data[ind==1,]
validation <- data[ind==2,]
test <- data[ind==3,]
colnames(squared_features) <-  c("sq_fixed_acidity", "sq_volatile_acidity", "sq_citric_acid", "sq_residual_sugar", "sq_chlorides",
"sq_free_sulfur_dioxide", "sq_total_sulfur_dioxide", "sq_density", "sq_pH", "sq_sulphates", "sq_alcohol")
names(squared_features) <-  c("sq_fixed_acidity", "sq_volatile_acidity", "sq_citric_acid", "sq_residual_sugar", "sq_chlorides",
"sq_free_sulfur_dioxide", "sq_total_sulfur_dioxide", "sq_density", "sq_pH", "sq_sulphates", "sq_alcohol")
data <- cbind(data[1:11], squared_features, data[12])
# split dataset 70/10/20
ind <- sample(3, nrow(data), replace=TRUE, prob= c(0.7,0.1,0.2))
training <- data[ind==1,]
validation <- data[ind==2,]
test <- data[ind==3,]
help("lm")
my_model_ridge <- lm.ridge(data$quality~.,
data)
install.packages("MASS")
#----------Stima dei parametri del modello----------#
library(MASS)
rm(list=ls())
# import data
data <- read.csv("wine.csv", header=F)
colnames(data) <- c("fixed_acidity", "volatile_acidity", "citric_acid", "residual_sugar", "chlorides",
"free_sulfur_dioxide", "total_sulfur_dioxide", "density", "pH", "sulphates", "alcohol", "quality")
# aggiungere quadrati delle feature
squared_features <- lapply( data[-12], function(x) (x^2))
names(squared_features) <-  c("sq_fixed_acidity", "sq_volatile_acidity", "sq_citric_acid", "sq_residual_sugar", "sq_chlorides",
"sq_free_sulfur_dioxide", "sq_total_sulfur_dioxide", "sq_density", "sq_pH", "sq_sulphates", "sq_alcohol")
data <- cbind(data[1:11], squared_features, data[12])
my_model_ridge <- lm.ridge(data$quality~.,
data,
lambda = 1)
help("lm.ridge")
#----------Stima dei parametri del modello----------#
library(MASS)
rm(list=ls())
# import data
data <- read.csv("wine.csv", header=F)
colnames(data) <- c("fixed_acidity", "volatile_acidity", "citric_acid", "residual_sugar", "chlorides",
"free_sulfur_dioxide", "total_sulfur_dioxide", "density", "pH", "sulphates", "alcohol", "quality")
# aggiungere quadrati delle feature
squared_features <- lapply( data[-12], function(x) (x^2))
names(squared_features) <-  c("sq_fixed_acidity", "sq_volatile_acidity", "sq_citric_acid", "sq_residual_sugar", "sq_chlorides",
"sq_free_sulfur_dioxide", "sq_total_sulfur_dioxide", "sq_density", "sq_pH", "sq_sulphates", "sq_alcohol")
data <- cbind(data[1:11], squared_features, data[12])
# split dataset 70/10/20
ind <- sample(3, nrow(data), replace=TRUE, prob= c(0.7,0.1,0.2))
training <- data[ind==1,]
validation <- data[ind==2,]
test <- data[ind==3,]
# TRAINING DEL MODELLO
# valutare errore sul validation set al variare di lambda -> ripeto il training del modello variando il valore e calcolo l'errore
my_model <- lm.ridge(formula = training$quality~.,
data = training,
lambda = 1)
# errori sul training e sul validation set
result_training <- predict(my_model, training)
install.packages("glmnet")
seq(0.0001, 1, length=5)
#----------Stima dei parametri del modello----------#
library(glmnet)
rm(list=ls())
# import data
data <- read.csv("wine.csv", header=F)
colnames(data) <- c("fixed_acidity", "volatile_acidity", "citric_acid", "residual_sugar", "chlorides",
"free_sulfur_dioxide", "total_sulfur_dioxide", "density", "pH", "sulphates", "alcohol", "quality")
# aggiungere quadrati delle feature
squared_features <- lapply( data[-12], function(x) (x^2))
names(squared_features) <-  c("sq_fixed_acidity", "sq_volatile_acidity", "sq_citric_acid", "sq_residual_sugar", "sq_chlorides",
"sq_free_sulfur_dioxide", "sq_total_sulfur_dioxide", "sq_density", "sq_pH", "sq_sulphates", "sq_alcohol")
data <- cbind(data[1:11], squared_features, data[12])
# split dataset 70/10/20
ind <- sample(3, nrow(data), replace=TRUE, prob= c(0.7,0.1,0.2))
training <- data[ind==1,]
validation <- data[ind==2,]
test <- data[ind==3,]
# TRAINING DEL MODELLO
# valutare errore sul validation set al variare di lambda -> ripeto il training del modello variando il valore e calcolo l'errore
ridge_model <- train(training$quality ~ .,
data = training,
method = "glmnet",
tuneGrid = expand.grid(alpha = 0,
# 0.000100 0.250075 0.500050 0.750025 1.000000
lambda = seq(0.0001, 1, length=5)
)
)
install.packages("caret")
library(caret)
#----------Stima dei parametri del modello----------#
library(glmnet)
library(caret)
rm(list=ls())
# import data
data <- read.csv("wine.csv", header=F)
colnames(data) <- c("fixed_acidity", "volatile_acidity", "citric_acid", "residual_sugar", "chlorides",
"free_sulfur_dioxide", "total_sulfur_dioxide", "density", "pH", "sulphates", "alcohol", "quality")
# aggiungere quadrati delle feature
squared_features <- lapply( data[-12], function(x) (x^2))
names(squared_features) <-  c("sq_fixed_acidity", "sq_volatile_acidity", "sq_citric_acid", "sq_residual_sugar", "sq_chlorides",
"sq_free_sulfur_dioxide", "sq_total_sulfur_dioxide", "sq_density", "sq_pH", "sq_sulphates", "sq_alcohol")
data <- cbind(data[1:11], squared_features, data[12])
# split dataset 70/10/20
ind <- sample(3, nrow(data), replace=TRUE, prob= c(0.7,0.1,0.2))
training <- data[ind==1,]
validation <- data[ind==2,]
#----------Stima dei parametri del modello----------#
library(glmnet)
library(caret)
rm(list=ls())
# import data
data <- read.csv("wine.csv", header=F)
colnames(data) <- c("fixed_acidity", "volatile_acidity", "citric_acid", "residual_sugar", "chlorides",
"free_sulfur_dioxide", "total_sulfur_dioxide", "density", "pH", "sulphates", "alcohol", "quality")
# aggiungere quadrati delle feature
squared_features <- lapply( data[-12], function(x) (x^2))
names(squared_features) <-  c("sq_fixed_acidity", "sq_volatile_acidity", "sq_citric_acid", "sq_residual_sugar", "sq_chlorides",
"sq_free_sulfur_dioxide", "sq_total_sulfur_dioxide", "sq_density", "sq_pH", "sq_sulphates", "sq_alcohol")
data <- cbind(data[1:11], squared_features, data[12])
# split dataset 70/10/20
ind <- sample(3, nrow(data), replace=TRUE, prob= c(0.7,0.1,0.2))
training <- data[ind==1,]
validation <- data[ind==2,]
test <- data[ind==3,]
# TRAINING DEL MODELLO
# valutare errore sul validation set al variare di lambda -> ripeto il training del modello variando il valore e calcolo l'errore
ridge_model <- train(training$quality ~ .,
data = training,
method = "glmnet",
tuneGrid = expand.grid(alpha = 0,
# 0.000100 0.250075 0.500050 0.750025 1.000000
lambda = seq(0.0001, 1, length=5)
)
)
# TRAINING DEL MODELLO
# valutare errore sul validation set al variare di lambda -> ripeto il training del modello variando il valore e calcolo l'errore
ridge_model <- train(quality ~ .,
data = training,
method = "glmnet",
tuneGrid = expand.grid(alpha = 0,
# 0.000100 0.250075 0.500050 0.750025 1.000000
lambda = seq(0.0001, 1, length=5)
)
)
# errori sul training e sul validation set
result_training <- predict(my_model, training)
# errori sul training e sul validation set
result_training <- predict(ridge_model, training)
result_validation <- predict(ridge_model, validation)
error_training <- result_training - training$quality
error_validation <- result_validation - validation$quality
View(ridge_model)
View(ridge_model)
ridge_model[["terms"]][[3]]
# RMSE su test set
result_test <- predict(ridge_model, test)
error_test <- result_1 - test$quality
RMSE <- sqrt(mean((error_test)^2))
# RMSE su test set
result_test <- predict(ridge_model, test)
error_test <- result_test - test$quality
RMSE <- sqrt(mean((error_test)^2))
# k-fold split TODO
# scrivere una funzione che effettui lo splitting k-folds e restituisca i dati necessari a realizzare gli esperimenti
library(glmnet)
library(caret)
custom <- trainControl(method = "repeatedcv",
number = 10,
repeats = 10)
# k-fold split TODO
# scrivere una funzione che effettui lo splitting k-folds e restituisca i dati necessari a realizzare gli esperimenti
library(glmnet)
library(caret)
custom <- trainControl(method = "repeatedcv",
number = 10,
repeats = 10)
cv_model <- train(quality ~ .,
training,
method = "lm",
trControl = custom)
cv_model$results
result_test_2 <- predict(cv_model, test)
ridge_model$finalModel
ridge_model$bestTune
#--------------------REGRESSIONE LINEARE MULTIVARIATA--------------------#
rm(list=ls())
# import data
data <- read.csv("wine.csv", header=F)
colnames(data) <- c("fixed_acidity", "volatile_acidity", "citric_acid", "residual_sugar", "chlorides",
"free_sulfur_dioxide", "total_sulfur_dioxide", "density", "pH", "sulphates", "alcohol", "quality")
# SCEGLIERE UN TIPO DI NORMALIZZAZIONE
# z-score normalization
mu <- apply(data[-12], 2, mean)
std <- apply(data[-12], 2, sd)
data[1:11] <- sweep(sweep(data[-12], 2L, mu), 2, std, "/") # come all'esercitazione
# TRAINING DEL MODELLO
my_model <- lm(data$quality~., data)
# APPLICARE IL MODELLO AL NUOVO SAMPLE
sample <- data.frame(t(c(6.0, 0.31, 0.47, 3.6, 0.067, 18.0, 42.0, 0.99549, 3.39, 0.66, 11.0)))
names(sample) <- c("fixed_acidity", "volatile_acidity", "citric_acid", "residual_sugar", "chlorides",
"free_sulfur_dioxide", "total_sulfur_dioxide", "density", "pH", "sulphates", "alcohol")
norm_sample <- sweep(sweep(sample, 2L, mu), 2, std, "/")
result_sample <- predict(my_model, norm_sample)
summary(my_model)
#----------Valutazione di un modello di regressione----------#
rm(list=ls())
# import data
data <- read.csv("wine.csv", header=F)
colnames(data) <- c("fixed_acidity", "volatile_acidity", "citric_acid", "residual_sugar", "chlorides",
"free_sulfur_dioxide", "total_sulfur_dioxide", "density", "pH", "sulphates", "alcohol", "quality")
# min-max normalization
min <- apply(data[-12], 2, min)
max <- apply(data[-12], 2, max)
diff <- max - min
data_mm <- data
#data_mm[1:11] <- lapply( data[-12], function(x) round((x-min(x))/(max(x)-min(x)), 1))
data_mm[1:11] <- sweep( sweep(data[-12], 2L, min), 2, diff, "/")
data_nn[1:11] <- sweep( sweep(data[-12], 2L, min), 2, diff, "/")
data_nn[1:11] <- sweep( sweep(data[-12], 2, min), 2, diff, "/")
data_nn <- data
#data_mm[1:11] <- lapply( data[-12], function(x) round((x-min(x))/(max(x)-min(x)), 1))
data_mm[1:11] <- sweep( sweep(data[-12], 2L, min), 2, diff, "/")
data_nn[1:11] <- sweep( sweep(data[-12], 2, min), 2, diff, "/")
