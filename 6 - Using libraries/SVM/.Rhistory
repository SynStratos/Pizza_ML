setwd("~/Machine Learning/SVM")
library(R.matlab)
library(e1071)
rm(list=ls())
sources <- c("-- inserire file --")
for (i in 1:length(sources)) {
source(sources[i])
}
# caricamento dei dati
data <- readMat("ex6data1.mat")
X <- data$X
y <- data$y
#
C <- 1;
#
model <- svm(X, y)
summary(model)
#
model <- svm(X, y, C)
summary(model)
#
C <- 10;
#
model <- svm(X, y, C)
summary(model)
#
model <- svm(X, y, cost=C)
summary(model)
#
model <- svm(X, y, cost=C, kernel="linear")
summary(model)
#
model <- svm(x=X, y=y, kernel="polynomial", cost=C)
summary(model)
#
model <- svm(x=X, y=y, kernel="linear", cost=C)
print(model)
summary(model)
#
dat <- data.frame(X, y)
model <- svm(x=X, y=y, kernel="linear", cost=C)
summary(model)
plot(model,dat )
#
dat <- data.frame(X, y)
model <- svm(x=X, y=y, data= dat,kernel="linear", cost=C)
summary(model)
plot(model,dat )
#
dat <- data.frame(X, y)
model <- svm(y ~ ., data=dat, kernel="linear", cost=C)
summary(model)
plot(model,dat )
#
C <- 10;
#
dat <- data.frame(X, y=as.factor(y))
model <- svm(y ~ ., data=dat, kernel="linear", cost=C)
summary(model)
plot(model,dat )
#
dat <- data.frame(X, y=as.factor(y))
model <- svm(y ~ ., data=dat, kernel="linear", cost=100)
summary(model)
plot(model,dat )
#
dat <- data.frame(X, y=as.factor(y))
model <- svm(y ~ ., data=dat, kernel="linear", cost=1)
summary(model)
plot(model,dat )
#
dat <- data.frame(X, y=as.factor(y))
model <- svm(y ~ ., data=dat, kernel="linear", cost=5)
summary(model)
plot(model,dat )
#
dat <- data.frame(X, y=as.factor(y))
model <- svm(y ~ ., data=dat, kernel="gaussian", cost=5)
#
dat <- data.frame(X, y=as.factor(y))
model <- svm(y ~ ., data=dat, kernel="polynomial", cost=5)
summary(model)
plot(model,dat )
#
dat <- data.frame(X, y=as.factor(y))
model <- svm(y ~ ., data=dat, kernel="polynomial", cost=5, scale=FALSE)
summary(model)
plot(model,dat )
#
dat <- data.frame(X, y=as.factor(y))
model <- svm(y ~ ., data=dat, kernel="radial", cost=5, scale=FALSE)
summary(model)
plot(model,dat )
#
dat <- data.frame(X, y=as.factor(y))
model <- svm(y ~ ., data=dat, kernel="linear", cost=5, scale=FALSE)
summary(model)
plot(model,dat )
#
dat <- data.frame(X, y=as.factor(y))
model <- svm(y ~ ., data=dat, kernel="linear", cost=1, scale=FALSE)
summary(model)
plot(model,dat )
#
dat <- data.frame(X, y=as.factor(y))
model <- svm(y ~ ., data=dat, kernel="linear", cost=100, scale=FALSE)
summary(model)
plot(model,dat )
#
dat <- data.frame(X, y=as.factor(y))
model <- svm(y ~ ., data=dat, kernel="linear", cost=-100, scale=FALSE)
summary(model)
plot(model,dat )
#
dat <- data.frame(X, y=as.factor(y))
model <- svm(y ~ ., data=dat, kernel="linear", cost=50, scale=FALSE)
summary(model)
plot(model,dat )
#
dat <- data.frame(X, y=as.factor(y))
model <- svm(y ~ ., data=dat, kernel="linear", cost=50)
summary(model)
plot(model,dat )
#
dat <- data.frame(X, y=as.factor(y))
model <- svm(y ~ ., data=dat, kernel="linear", cost=100)
summary(model)
plot(model,dat )
#
dat <- data.frame(X, y=as.factor(y))
model <- svm(y ~ ., data=dat, kernel="linear", cost=100, scale=FALSE)
summary(model)
plot(model,dat )
#
dat <- data.frame(X, y=as.factor(y))
model <- svm(y ~ ., data=dat, kernel="linear", cost=100, scale=FALSE)
summary(model)
plot(model,dat )
#
dat <- data.frame(X, y=as.factor(y))
model <- svm(y ~ ., data=dat, kernel="linear", cost=1, scale=FALSE)
summary(model)
plot(model,dat )
#
dat <- data.frame(X, y=as.factor(y))
model <- svm(y ~ ., data=dat, kernel="linear", cost=1)
summary(model)
plot(model,dat )
#
dat <- data.frame(X, y=as.factor(y))
model <- svm(y ~ ., data=dat, kernel="linear", cost=1, scale=FALSE)
summary(model)
plot(model,dat )
make.grid = function(x, n = 75) {
grange = apply(x, 2, range)
x1 = seq(from = grange[1,1], to = grange[2,1], length = n)
x2 = seq(from = grange[1,2], to = grange[2,2], length = n)
expand.grid(X1 = x1, X2 = x2)
}
xgrid = make.grid(x)
xgrid[1:10,]
ygrid = predict(svmfit, xgrid)
plot(xgrid, col = c("red","blue")[as.numeric(ygrid)], pch = 20, cex = .2)
points(x, col = y + 3, pch = 19)
points(x[svmfit$index,], pch = 5, cex = 2)
points(x[svmfit$index,], pch = 5, cex = 2)
beta = drop(t(svmfit$coefs)%*%x[svmfit$index,])
beta0 = svmfit$rho
plot(xgrid, col = c("red", "blue")[as.numeric(ygrid)], pch = 20, cex = .2)
points(x, col = y + 3, pch = 19)
points(x[svmfit$index,], pch = 5, cex = 2)
abline(beta0 / beta[2], -beta[1] / beta[2])
abline((beta0 - 1) / beta[2], -beta[1] / beta[2], lty = 2)
abline((beta0 + 1) / beta[2], -beta[1] / beta[2], lty = 2)
source('~/Machine Learning/SVM/main.R')
#
dat <- data.frame(X, y=as.factor(y))
model <- svm( data=dat, kernel="linear", cost=1, scale=FALSE)
summary(model)
#
C <- 100;
#
dat <- data.frame(X, y=as.factor(y))
source('~/Machine Learning/SVM/main.R')
rm(list=ls())
sources <- c("-- inserire file --")
for (i in 1:length(sources)) {
source(sources[i])
}
# caricamento dei dati
data <- readMat("ex6data1.mat")
X <- data$X
y <- data$y
#
C <- 100;
#
dat <- data.frame(X, y=as.factor(y))
model <- svm( data=dat, kernel="linear", cost=1, scale=FALSE)
#
dat <- data.frame(X, y=as.factor(y))
model <- svm(y ~ ., data=dat, kernel="linear", cost=1, scale=FALSE)
summary(model)
plot(model,dat )
data <- readMat("ex6data2.mat")
X2 <- data$X
y2 <- data$y
# implementazione gaussian kernel
dat2 <- data.frame(X2, y2=as.factor(y))
# implementazione gaussian kernel
dat2 <- data.frame(X2, y2=as.factor(y2))
model2 <- svm(y ~ ., data=dat2, kernel="polynomial", cost=C, scale=FALSE)
# implementazione gaussian kernel
dat2 <- data.frame(X2, y2=as.factor(y2))
model2 <- svm(y2 ~ ., data=dat2, kernel="polynomial", cost=C, scale=FALSE)
summary(model2)
plot(model2,dat2)
# implementazione gaussian kernel
dat2 <- data.frame(X2, y2=as.factor(y2))
model2 <- svm(y2 ~ ., data=dat2, kernel="polynomial", cost=10, scale=FALSE)
summary(model2)
plot(model2,dat2)
# implementazione gaussian kernel
dat2 <- data.frame(X2, y2=as.factor(y2))
model2 <- svm(y2 ~ ., data=dat2, kernel="polynomial", cost=100, scale=FALSE)
summary(model2)
plot(model2,dat2)
# implementazione gaussian kernel
dat2 <- data.frame(X2, y2=as.factor(y2))
model2 <- svm(y2 ~ ., data=dat2, kernel="polynomial", cost=100, coef0=0.1 , scale=FALSE)
summary(model2)
plot(model2,dat2)
# implementazione gaussian kernel
dat2 <- data.frame(X2, y2=as.factor(y2))
model2 <- svm(y2 ~ ., data=dat2, kernel="polynomial", cost=100, coef0=0.1, degree=5, scale=FALSE)
summary(model2)
plot(model2,dat2)
# implementazione gaussian kernel
dat2 <- data.frame(X2, y2=as.factor(y2))
model2 <- svm(y2 ~ ., data=dat2, kernel="polynomial", cost=100, coef0=0.01, degree=10, scale=FALSE)
summary(model2)
plot(model2,dat2)
# implementazione gaussian kernel
dat2 <- data.frame(X2, y2=as.factor(y2))
model2 <- svm(y2 ~ ., data=dat2, kernel="polynomial", cost=100, coef0=0, degree=10, scale=FALSE)
summary(model2)
plot(model2,dat2)
# implementazione gaussian kernel
dat2 <- data.frame(X2, y2=as.factor(y2))
model2 <- svm(y2 ~ ., data=dat2, kernel="polynomial", cost=100, coef0=0, degree=4, scale=FALSE)
summary(model2)
plot(model2,dat2)
# implementazione gaussian kernel
dat2 <- data.frame(X2, y2=as.factor(y2))
model2 <- svm(y2 ~ ., data=dat2, kernel="polynomial", cost=100, coef0=3, degree=4, scale=FALSE)
summary(model2)
plot(model2,dat2)
# implementazione gaussian kernel
dat2 <- data.frame(X2, y2=as.factor(y2))
model2 <- svm(y2 ~ ., data=dat2, kernel="polynomial", cost=100, coef0=3, degree=10, scale=FALSE)
summary(model2)
plot(model2,dat2)
# implementazione gaussian kernel
dat2 <- data.frame(X2, y2=as.factor(y2))
model2 <- svm(y2 ~ ., data=dat2, kernel="polynomial", cost=1, coef0=3, degree=10, scale=FALSE)
summary(model2)
plot(model2,dat2)
# implementazione gaussian kernel
dat2 <- data.frame(X2, y2=as.factor(y2))
model2 <- svm(y2 ~ ., data=dat2, kernel="polynomial", cost=1, coef0=30, degree=10, scale=FALSE)
summary(model2)
plot(model2,dat2)
# implementazione gaussian kernel
dat2 <- data.frame(X2, y2=as.factor(y2))
model2 <- svm(y2 ~ ., data=dat2, kernel="polynomial", cost=1, coef0=0, degree=10, scale=FALSE)
summary(model2)
plot(model2,dat2)
# implementazione gaussian kernel
dat2 <- data.frame(X2, y2=as.factor(y2))
model2 <- svm(y2 ~ ., data=dat2, kernel="polynomial", cost=1, coef0=3, degree=10, scale=FALSE)
summary(model2)
plot(model2,dat2)
# implementazione gaussian kernel
dat2 <- data.frame(X2, y2=as.factor(y2))
model2 <- svm(y2 ~ ., data=dat2, kernel="polynomial", cost=1, coef0=3, degree=11, scale=FALSE)
summary(model2)
plot(model2,dat2)
# implementazione gaussian kernel
dat2 <- data.frame(X2, y2=as.factor(y2))
model2 <- svm(y2 ~ ., data=dat2, kernel="polynomial", cost=1, coef0=3, degree=9, scale=FALSE)
summary(model2)
plot(model2,dat2)
# implementazione gaussian kernel
dat2 <- data.frame(X2, y2=as.factor(y2))
model2 <- svm(y2 ~ ., data=dat2, kernel="polynomial", cost=1, coef0=3, degree=10, scale=FALSE)
summary(model2)
plot(model2,dat2)
data <- readMat("ex6data3.mat")
X2 <- data$X
y2 <- data$y
# implementazione gaussian kernel
dat2 <- data.frame(X2, y2=as.factor(y2))
model2 <- svm(y2 ~ ., data=dat2, kernel="polynomial", cost=1, coef0=3, degree=10, scale=FALSE)
summary(model2)
plot(model2,dat2)
source('~/Machine Learning/SVM/main.R')
source('~/Machine Learning/SVM/main.R')
library(e1071)
library(mlbench)
install.packages("mlbench")
predi <- predict(model, dat)
predi <- predict(model, dat)
summary(predi)
