library(neuralnet)
data <- read.csv("candy_2.csv", HEADER=FALSE)
data <- read.csv("candy_2.csv", header=FALSE)
colnames(data) <- c("a", "b")
colnames(data) <- c("caramel", "peanutyalmondy", "nougat", "crispedricewafer", "hard", "bar", "pluribus", "sugarpercent", "pricepercent", "winpercent")
colnames(data) <- c("caramel", "peanutyalmondy", "nougat", "crispedricewafer", "hard", "bar", "pluribus", "sugarpercent", "pricepercent", "winpercent", "choco", "fruit", "else")
colnames(data) <- c("caramel", "peanutyalmondy", "nougat", "crispedricewafer", "hard", "bar", "pluribus", "sugarpercent", "pricepercent", "winpercent", "choco", "fruit", "other")
data$winpercent <- ( data$winpercent - min(data$winpercent))/(max(data$winpercent) - min(data$winpercent))
set.seed(222)
ind <- sample(2, nrow(data), replace=TRUE, prob= c(0.7,0.3))
training <- data[ind==1,]
test <- data[ind==2,]
X <- training[,1:10]
y1 <- training[,11]
y2 <- training[,12]
y3 <- training[,13]
model <- neuralnet(choco~.,
data=training,
hidden=5,
rep=2)
model <- neuralnet(y1~.,
data = training,
hidden=5,
rep=2)
model <- neuralnet(choco~hard+bar,
data = training,
hidden=5,
rep=2)
dat <- data.frame(X, y1=as.factor(y1))
model <- neuralnet(y1~.,
data = dat,
hidden=5,
rep=2)
model <- neuralnet(choco~X,
data = training,
hidden=5,
rep=2)
rm(list=ls())
data <- read.csv("candy_2.csv", header=FALSE)
colnames(data) <- c("caramel", "peanutyalmondy", "nougat", "crispedricewafer", "hard", "bar", "pluribus", "sugarpercent", "pricepercent", "winpercent", "choco", "fruit", "other")
data$winpercent <- ( data$winpercent - min(data$winpercent))/(max(data$winpercent) - min(data$winpercent))
set.seed(222)
ind <- sample(2, nrow(data), replace=TRUE, prob= c(0.7,0.3))
training <- data[ind==1,]
test <- data[ind==2,]
X <- training[,1:10]
y1 <- training[,11]
y2 <- training[,12]
y3 <- training[,13]
model <- neuralnet(choco~X,
data = training,
hidden=5,
rep=2)
model <- neuralnet(choco~sum(X),
data = training,
hidden=5,
rep=2)
View(data)
View(data)
View(X)
View(X)
model <- neuralnet(choco + fruit + other ~
caramel + peanutyalmondy + nougat + crispedricewafer + hard +
bar + pluribus + sugarpercent + pricepercent + winpercent,
data = training,
hidden=5,
rep=2)
plot(model)
model <- neuralnet(choco + fruit + other ~
caramel + peanutyalmondy + nougat + crispedricewafer + hard +
bar + pluribus + sugarpercent + pricepercent + winpercent,
data = training,
hidden=c(5,5),
rep=2)
plot(model)
X <- test[,1:10]
output <- compute(model, X)
p1 <- output$net.result
View(p1)
View(p1)
result1 <- which.max(p1)
result1 <- which.max(result1)
result1 <- which.max(p1[:,])
result1 <- which.max(p1[1:length(p1),])
result1 <- which.max(p1[,])
summary(p1)
result1 <- which.max(p1[1,])
p1 <- output$net.result
result1 <- p1[[length(p1)]]
result1 <- which.max(p1[1:10,])
result1 <- which.max(p1[1:9,])
result1 <- which.max(p1[,1:3])
result1 <- max.col(p1)
summary(resul1)
summary(result1)
print(result1)
test2 <- cbind(pred1, pred2, pred3)
pred1 <- c(0, 0, 0, 0, 0, 0, 1, 0.31299999, 0.31299999, 44.375519)
pred2 <- c(1, 0, 0, 0, 1, 0, 0, 0.186, 0.26699999, 41.904308)
pred3 <- c(0, 0, 0, 1, 0, 0, 1, 0.87199998, 0.84799999, 49.524113)
test2 <- cbind(pred1, pred2, pred3)
View(test2)
View(test2)
pred1 <- cbind(0, 0, 0, 0, 0, 0, 1, 0.31299999, 0.31299999, 44.375519)
pred1 <- cbind(0, 0, 0, 0, 0, 0, 1, 0.31299999, 0.31299999, 44.375519)
pred2 <- cbind(1, 0, 0, 0, 1, 0, 0, 0.186, 0.26699999, 41.904308)
pred3 <- cbind(0, 0, 0, 1, 0, 0, 1, 0.87199998, 0.84799999, 49.524113)
test2 <- cbind(pred1, pred2, pred3)
test2 <- c(pred1, pred2, pred3)
View(test)
View(pred1)
View(pred1)
test2 <- rbind(pred1, pred2, pred3)
View(test2)
View(test2)
test2 <- rbind(pred1, pred2, pred3)
output2 <- compute(model, test2)
p2 <- output2$net.result
result2 <- max.col(p2)
head(choco)
head(training$choco)
# traino il modello della rete neurale
frm <- as.formula(paste(names(training)[,11:13], " ~ ", paste(names(training)[,1:10], collapse= "+")))
frm <- as.formula(paste(names(training)[11:13], " ~ ", paste(names(training)[,1:10], collapse= "+")))
frm <- as.formula(paste(names(training)[11:13], " ~ ", paste(names(training)[1:10], collapse= "+")))
frm <- as.formula(paste(names(training)[11:14], " ~ ", paste(names(training)[1:10], collapse= "+")))
frm <- as.formula(paste(names(training)[11:14], " ~ ", paste(names(training)[1:10], collapse= "+")))
frm <- as.formula(paste(names(training)[11:13], collapse= "+"), " ~ ", paste(names(training)[1:10], collapse= "+"))
frm <- as.formula(paste(paste(names(training)[11:13], collapse= "+"), " ~ ", paste(names(training)[1:10], collapse= "+")))
model <- neuralnet(formula = my_formula,
data = training,
hidden=c(5,5),
rep=2)
my_formula<- as.formula(paste(paste(names(training)[11:13], collapse= "+"), " ~ ", paste(names(training)[1:10], collapse= "+")))
model <- neuralnet(formula = my_formula,
data = training,
hidden=c(5,5),
rep=2)
plot(model)
library(neuralnet)
rm(list=ls())
data <- read.csv("candy_2.csv", header=FALSE)
# rinomino le colonne perchÃ¨ altrimenti "toffa"
colnames(data) <- c("caramel", "peanutyalmondy", "nougat", "crispedricewafer", "hard", "bar", "pluribus", "sugarpercent", "pricepercent", "winpercent", "choco", "fruit", "other")
# normalizzo la colonna con i valori brutti
data$winpercent <- ( data$winpercent - min(data$winpercent))/(max(data$winpercent) - min(data$winpercent))
# creo training set e test set
set.seed(222)
ind <- sample(2, nrow(data), replace=TRUE, prob= c(0.7,0.3))
training <- data[ind==1,]
test <- data[ind==2,]
my_formula<- as.formula(paste(paste(names(training)[11:13], collapse= "+"), " ~ ", paste(names(training)[1:10], collapse= "+")))
my_formula<- as.formula(paste(paste(names(training)[11:13], collapse= "+"), " ~ ", paste(names(training)[1:10], collapse= "+")))
model <- neuralnet(formula = my_formula,
data = training,
hidden=c(5,5),
rep=2)
plot(model)
model <- neuralnet(formula = my_formula,
data = training,
hidden=c(5,5),
rep=2)
# provo sul test set generato in precedenza
X <- test[,1:10]
output <- compute(model, X)
p1 <- output$net.result
result1 <- max.col(p1)
